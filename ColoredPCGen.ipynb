{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Point Cloud from depth image\n",
    "---\n",
    "This notebook takes a depth and rgb image and converts it into a point cloud to display.\n",
    "\n",
    "First thing to do is import all needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install imageio\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "Next step is to define callibration data for the camera. This data is not perfect for our camera but it does the job for now.\n",
    "\n",
    "Data is provided via the [NYU Depth Dataset](https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth camera parameters:\n",
    "FX_DEPTH = 5.8262448167737955e+02\n",
    "FY_DEPTH = 5.8269103270988637e+02\n",
    "CX_DEPTH = 3.1304475870804731e+02\n",
    "CY_DEPTH = 2.3844389626620386e+02\n",
    "\n",
    "# RGB camera parameters:\n",
    "FX_RGB = 5.1885790117450188e+02\n",
    "FY_RGB = 5.1946961112127485e+02\n",
    "CX_RGB = 3.2558244941119034e+0\n",
    "CY_RGB = 2.5373616633400465e+02\n",
    "\n",
    "# Rotation matrix:\n",
    "R = -np.array([[9.9997798940829263e-01, 5.0518419386157446e-03, 4.3011152014118693e-03],\n",
    "                   [-5.0359919480810989e-03, 9.9998051861143999e-01, -3.6879781309514218e-03],\n",
    "                   [- 4.3196624923060242e-03, 3.6662365748484798e-03, 9.9998394948385538e-01]])\n",
    "# Translation vector:\n",
    "T = np.array([2.5031875059141302e-02, -2.9342312935846411e-04, 6.6238747008330102e-04])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the image is the next part. This takes the image in as a numpy array. After, we display some usefull data about the image array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image and display basic information\n",
    "depth_image = iio.imread(\"./images/png/depth/2023-11-09.16.25.23_depth_image.png\")\n",
    "rgb_image = iio.imread(\"./images/png/color/2023-11-09.16.25.23_color_image.png\")\n",
    "\n",
    "print(f\"Image resolution: {depth_image.shape}\")\n",
    "print(f\"Data type: {depth_image.dtype}\")\n",
    "print(f\"Min value: {np.min(depth_image)}\")\n",
    "print(f\"Max value: {np.max(depth_image)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is calculating the grayscale image that we will need to generate the pointcloud. For development and debugging reasons, this will exported to a png file as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_grayscale = np.array(256 * depth_image / 0x0fff, dtype=np.uint8)\n",
    "iio.imwrite(f\"output/grayscale/grayscale_{datetime.datetime.now().strftime('%Y%m%d_%H_%M_%S.%f')[:-3]}.png\", depth_grayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is purely go show the depth image and the rgb image next to each other. This is an easy way to quickly check if the correct images are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display depth and grayscale image:\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "axs[0].imshow(depth_image, cmap=\"gray\")\n",
    "axs[0].set_title('Depth image')\n",
    "axs[1].imshow(rgb_image)\n",
    "axs[1].set_title('RGB image')\n",
    "axs[2].imshow(depth_grayscale, cmap=\"gray\")\n",
    "axs[2].set_title('Depth grayscale image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the point cloud\n",
    "Only two things left: generating the point cloud point coordinates and displaying the point cloud. The next cell does the first thing. It takes into account the callibration data defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, index = depth_image.shape\n",
    "\n",
    "colors = []\n",
    "pcd = []\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        \"\"\"\n",
    "            Convert the pixel from depth coordinate system\n",
    "            to depth sensor 3D coordinate system\n",
    "        \"\"\"\n",
    "        z = depth_image[i][j]\n",
    "        x = (j - CX_DEPTH) * z / FX_DEPTH\n",
    "        y = (i - CY_DEPTH) * z / FY_DEPTH\n",
    "\n",
    "        \"\"\"\n",
    "            Convert the point from depth sensor 3D coordinate system\n",
    "            to rgb camera coordinate system:\n",
    "        \"\"\"\n",
    "        [x_RGB, y_RGB, z_RGB] = np.linalg.inv(R).dot([x, y, z]) - np.linalg.inv(R).dot(T)\n",
    "\n",
    "        \"\"\"\n",
    "            Convert from rgb camera coordinates system\n",
    "            to rgb image coordinates system:\n",
    "        \"\"\"\n",
    "        j_rgb = int((x_RGB[0] * FX_RGB) / z_RGB[0] + CX_RGB + width / 2)\n",
    "        i_rgb = int((y_RGB[0] * FY_RGB) / z_RGB[0] + CY_RGB)\n",
    "\n",
    "        # Add point to point cloud:\n",
    "        pcd.append([x[0], y[0], z[0]])\n",
    "\n",
    "        # Add the color of the pixel if it exists:\n",
    "        if 0 <= j_rgb < width and 0 <= i_rgb < height:\n",
    "            colors.append(rgb_image[i_rgb][j_rgb] / 255)\n",
    "        else:\n",
    "            colors.append([0., 0., 0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step: Generate and show the point cloud itself. This cell converts the array of point coordinates to a 3d vector type. This is drawn and visualised with the open3d module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_o3d = o3d.geometry.PointCloud()\n",
    "pcd_o3d.points = o3d.utility.Vector3dVector(pcd)\n",
    "pcd_o3d.colors = o3d.utility.Vector3dVector(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the point cloud\n",
    "\n",
    "In the last steps, all the data got calculated and the point was generated. In this extra part, the point cloud can be either saved or displayed.  \n",
    "First displaying the point cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd_o3d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, saving the point cloud as a ply file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.io.write_point_cloud(f\"output/pointcloud/pointcloud_{datetime.datetime.now().strftime('%Y%m%d_%H:%M:%S.%f')[:-3]}.ply\", pcd_o3d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
